{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QHnVupBBn9eR"
   },
   "source": [
    "# Training segmwntation model to find task numbers using Detectron2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vM54r6jlKTII"
   },
   "source": [
    "# Install detectron2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 3331,
     "status": "ok",
     "timestamp": 1611053361685,
     "user": {
      "displayName": "Бузин Глеб Борисович",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gie_U-wtf3incY-prfOKwdA_OjgoEEDivcIJ7cJ=s64",
      "userId": "05572211529618585037"
     },
     "user_tz": -180
    },
    "id": "9_FzH13EjseR",
    "outputId": "6622436b-a0af-4c30-edd5-a68b30f9729f",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.insert(0, os.path.abspath('../detectron2'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 5703,
     "status": "ok",
     "timestamp": 1611053364070,
     "user": {
      "displayName": "Бузин Глеб Борисович",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gie_U-wtf3incY-prfOKwdA_OjgoEEDivcIJ7cJ=s64",
      "userId": "05572211529618585037"
     },
     "user_tz": -180
    },
    "id": "ZyAvNCJMmvFF",
    "outputId": "0c4f3489-2850-4086-9870-bd807301d082",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Some basic setup:\n",
    "# Setup detectron2 logger\n",
    "from detectron2.utils.logger import setup_logger\n",
    "setup_logger()\n",
    "\n",
    "# import some common libraries\n",
    "import numpy as np\n",
    "import os, json, cv2, random\n",
    "from IPython import display\n",
    "import PIL\n",
    "\n",
    "\n",
    "# import some common detectron2 utilities\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultPredictor,DefaultTrainer\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import MetadataCatalog, DatasetCatalog\n",
    "\n",
    "\n",
    "def cv2_imshow(a):\n",
    "    \"\"\"A replacement for cv2.imshow() for use in Jupyter notebooks.\n",
    "    Args:\n",
    "    a : np.ndarray. shape (N, M) or (N, M, 1) is an NxM grayscale image. shape\n",
    "      (N, M, 3) is an NxM BGR color image. shape (N, M, 4) is an NxM BGRA color\n",
    "      image.\n",
    "    \"\"\"\n",
    "    a = a.clip(0, 255).astype('uint8')\n",
    "    # cv2 stores colors as BGR; convert to RGB\n",
    "    if a.ndim == 3:\n",
    "        if a.shape[2] == 4:\n",
    "            a = cv2.cvtColor(a, cv2.COLOR_BGRA2RGBA)\n",
    "        else:\n",
    "            a = cv2.cvtColor(a, cv2.COLOR_BGR2RGB)\n",
    "    display.display(PIL.Image.fromarray(a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b2bjrfb2LDeo"
   },
   "source": [
    "# Train on a custom dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tjbUIhSxUdm_"
   },
   "source": [
    "## Prepare the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path=r\"C:\\Users\\main laptop\\programation\\Study\\baechlor arbeit\\bollard\\images\\all\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from detectron2.data.datasets import register_coco_instances\n",
    "register_coco_instances(\"my_dataset_train\", {}, r\"C:\\Users\\main laptop\\programation\\Study\\baechlor arbeit\\bollard\\images\\bollard6\\instances_bollard6.json\"\n",
    "                        ,r\"C:\\Users\\main laptop\\programation\\Study\\baechlor arbeit\\bollard\\images\\bollard6\\pollerCroppedDirection\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### evaluatioin dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To verify the data loading is correct, let's visualize the annotations of randomly selected samples in the training set:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 5316,
     "status": "ok",
     "timestamp": 1611053852366,
     "user": {
      "displayName": "Бузин Глеб Борисович",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gie_U-wtf3incY-prfOKwdA_OjgoEEDivcIJ7cJ=s64",
      "userId": "05572211529618585037"
     },
     "user_tz": -180
    },
    "id": "UkNbUzUOLYf0",
    "outputId": "ecfad30d-2c2c-4681-c6d7-f25bf3269fa8",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#visualize training data\n",
    "train_metadata = MetadataCatalog.get(\"my_dataset_train\")\n",
    "dataset_dicts = DatasetCatalog.get(\"my_dataset_train\")\n",
    "\n",
    "import random\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "\n",
    "for d in dataset_dicts:\n",
    "    print(d[\"file_name\"])\n",
    "    img = cv2.imread(d[\"file_name\"])\n",
    "    visualizer = Visualizer(img[:, :, ::-1], metadata=train_metadata, scale=0.5)\n",
    "    vis = visualizer.draw_dataset_dict(d)\n",
    "    cv2_imshow(vis.get_image()[:, :, ::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "im = cv2.imread(r\"C:\\Users\\main laptop\\programation\\Study\\baechlor arbeit\\bollard\\images\\bollard6\\pollerCroppedDirection\\20240825_144317_fixing_5.jpg\")\n",
    "\n",
    "\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES =1\n",
    "\n",
    "# Create predictor\n",
    "predictor = DefaultPredictor(cfg)\n",
    "# Make prediction\n",
    "outputs = predictor(im)\n",
    "v = Visualizer(im[:, :, ::-1], train_metadata, scale=1.2)\n",
    "v = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
    "plt.figure(figsize = (14, 10))\n",
    "plt.imshow(cv2.cvtColor(v.get_image()[:, :, ::-1], cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wlqXIXXhW8dA"
   },
   "source": [
    "## Train!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ouput directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = get_cfg()\n",
    "cfg.OUTPUT_DIR = os.path.join(dataset_path,\"output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = get_cfg()\n",
    "cfg.OUTPUT_DIR = r\"C:\\Users\\main laptop\\programation\\Study\\baechlor arbeit\\bollard\\datasets\\big_bollard_dataset\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train without validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 144708,
     "status": "ok",
     "timestamp": 1611054050210,
     "user": {
      "displayName": "Бузин Глеб Борисович",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gie_U-wtf3incY-prfOKwdA_OjgoEEDivcIJ7cJ=s64",
      "userId": "05572211529618585037"
     },
     "user_tz": -180
    },
    "id": "7unkuuiqLdqd",
    "outputId": "fc5de772-ea0f-4917-ecd7-519dd7838e07",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "cfg= get_cfg()\n",
    "cfg.OUTPUT_DIR = r\"C:\\Users\\main laptop\\programation\\Study\\baechlor arbeit\\segmentation model\\output\"\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml\"))\n",
    "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml\") \n",
    "cfg.DATASETS.TRAIN = (\"my_dataset_train\",)\n",
    "cfg.DATALOADER.NUM_WORKERS = 2\n",
    "cfg.SOLVER.IMS_PER_BATCH = 2\n",
    "cfg.DATASETS.TEST = (\"my_dataset_train\",)\n",
    "cfg.SOLVER.BASE_LR =0.00025  \n",
    "cfg.SOLVER.MAX_ITER = 1000\n",
    "cfg.TEST.EVAL_PERIOD = 201\n",
    "cfg.SOLVER.CHECKPOINT_PERIOD = 200\n",
    "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 512  \n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES =1\n",
    "cfg.INPUT.MASK_FORMAT = \"bitmask\"\n",
    "trainer = DefaultTrainer(cfg) \n",
    "trainer.resume_or_load(resume=False)\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train with validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.evaluation import COCOEvaluator\n",
    "\n",
    "class CocoTrainer(DefaultTrainer):\n",
    "    @classmethod\n",
    "    def build_evaluator(cls, cfg, dataset_name, output_folder=None):\n",
    "        if output_folder is None:\n",
    "            os.makedirs(\"coco_eval\", exist_ok=True)\n",
    "            output_folder = \"coco_eval\"\n",
    "        return COCOEvaluator(dataset_name, cfg, False, output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg= get_cfg()\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml\"))\n",
    "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml\")  \n",
    "cfg.DATASETS.TRAIN = (\"my_dataset_train\",)\n",
    "cfg.DATASETS.TEST = (\"my_dataset_validation\",)\n",
    "cfg.DATALOADER.NUM_WORKERS = 2\n",
    "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml\")  \n",
    "cfg.SOLVER.IMS_PER_BATCH = 2\n",
    "cfg.SOLVER.BASE_LR = 0.0025 \n",
    "cfg.SOLVER.MAX_ITER = 10000\n",
    "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 512  \n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES =2\n",
    "cfg.TEST.EVAL_PERIOD = 500 \n",
    "cfg.SOLVER.CHECKPOINT_PERIOD = 500\n",
    "trainer = CocoTrainer(cfg) \n",
    "\n",
    "trainer.resume_or_load(resume=False)\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Continue training from checkpoint\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### with validation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.merge_from_file(os.path.join(cfg.OUTPUT_DIR,\"config15000_29.07.yaml\"))\n",
    "cfg.DATASETS.TRAIN = (\"my_dataset_train\",)\n",
    "cfg.DATASETS.TEST = (\"my_dataset_validation\",)\n",
    "cfg.DATALOADER.NUM_WORKERS = 2\n",
    "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR,\"model_final.pth\")   # Let training initialize from model zoo\n",
    "cfg.SOLVER.IMS_PER_BATCH = 2\n",
    "cfg.SOLVER.BASE_LR = 0.0025  # pick a good LR\n",
    "cfg.SOLVER.MAX_ITER = 20000   \n",
    "cfg.SOLVER.CHECKPOINT_PERIOD = 500\n",
    "cfg.TEST.EVAL_PERIOD= 500\n",
    "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 512   # faster, and good enough for this toy dataset (default: 512)\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES =2  \n",
    "trainer = CocoTrainer(cfg) \n",
    "trainer.resume_or_load(resume=True)\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### without validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.merge_from_file(os.path.join(cfg.OUTPUT_DIR,\"config.yaml\"))\n",
    "cfg.DATASETS.TRAIN = (\"my_dataset_train\",)\n",
    "cfg.DATALOADER.NUM_WORKERS = 2\n",
    "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR,\"model_final.pth\")   # Let training initialize from model zoo\n",
    "cfg.SOLVER.IMS_PER_BATCH = 2\n",
    "cfg.SOLVER.BASE_LR = 0.0025  # pick a good LR\n",
    "cfg.SOLVER.MAX_ITER = 600   \n",
    "cfg.SOLVER.CHECKPOINT_PERIOD = 100\n",
    "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 512   # faster, and good enough for this toy dataset (default: 512)\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES =2  \n",
    "trainer = DefaultTrainer(cfg) \n",
    "trainer.resume_or_load(resume=True)\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.OUTPUT_DIR = r\"C:\\Users\\main laptop\\programation\\Study\\baechlor arbeit\\segmentation model\\output\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.save(trainer.model.state_dict(),r\"C:\\Users\\main laptop\\programation\\Study\\baechlor arbeit\\segmentation model\\output\\model_500.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save config\n",
    "with open(os.path.join(cfg.OUTPUT_DIR, \"config1000.yaml\"), \"w\") as f:\n",
    "    f.write(cfg.dump())  # Save as YAML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 805,
     "status": "ok",
     "timestamp": 1611054055890,
     "user": {
      "displayName": "Бузин Глеб Борисович",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gie_U-wtf3incY-prfOKwdA_OjgoEEDivcIJ7cJ=s64",
      "userId": "05572211529618585037"
     },
     "user_tz": -180
    },
    "id": "hBXeH8UXFcqU",
    "outputId": "4b5d2c87-e93a-486f-8fe6-1449b465e680",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-5b763cdeadd8fee5\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-5b763cdeadd8fee5\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir r\"C:\\Users\\main laptop\\programation\\Study\\baechlor arbeit\\segmentation model\\output\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0e4vdDIOXyxF"
   },
   "source": [
    "# Inference & evaluation using the trained model\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qWq1XHfDWiXO"
   },
   "source": [
    "## load test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.data.datasets import register_coco_instances\n",
    "register_coco_instances(\"my_dataset_test\", {}, os.path.join(dataset_path,\"test_annotations.json\"), \n",
    "                     os.path.join(dataset_path,\"test\")) \n",
    "test_metadata = MetadataCatalog.get(\"my_dataset_test\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.data.datasets import register_coco_instances\n",
    "register_coco_instances(\"my_dataset_test\", {},r\"C:\\Users\\main laptop\\programation\\Study\\baechlor arbeit\\bollard\\images\\bollard6\\instances_bollard6.json\",\n",
    "                        r\"C:\\Users\\main laptop\\programation\\Study\\baechlor arbeit\\bollard\\images\\bollard6\\pollerCroppedDirection\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "cfg.merge_from_file( os.path.join(cfg.OUTPUT_DIR,\"config15000_29.07.yaml\"))\n",
    "cfg.MODEL.WEIGHTS =  os.path.join(cfg.OUTPUT_DIR,\"model_0014499.pth\")\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.7\n",
    "predictor = DefaultPredictor(cfg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[10/16 18:57:34 d2.checkpoint.detection_checkpoint]: \u001b[0m[DetectionCheckpointer] Loading from C:\\Users\\main laptop\\programation\\Study\\baechlor arbeit\\segmentation model\\output\\model_0000999.pth ...\n"
     ]
    }
   ],
   "source": [
    "cfg= get_cfg()\n",
    "cfg.merge_from_file(r\"C:\\Users\\main laptop\\programation\\Study\\baechlor arbeit\\segmentation model\\output\\config1000.yaml\")\n",
    "cfg.MODEL.WEIGHTS =  os.path.join(r\"C:\\Users\\main laptop\\programation\\Study\\baechlor arbeit\\segmentation model\\output\\model_0000999.pth\")\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.7   # set a custom testing threshold\n",
    "predictor = DefaultPredictor(cfg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kblA1IyFvWbT"
   },
   "source": [
    "## evaluate its performance using AP metric implemented in COCO API.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[10/16 18:57:36 d2.checkpoint.detection_checkpoint]: \u001b[0m[DetectionCheckpointer] Loading from C:\\Users\\main laptop\\programation\\Study\\baechlor arbeit\\segmentation model\\output\\model_0000999.pth ...\n",
      "\u001b[32m[10/16 18:57:36 d2.evaluation.coco_evaluation]: \u001b[0mFast COCO eval is not built. Falling back to official COCO eval.\n",
      "\u001b[32m[10/16 18:57:36 d2.data.datasets.coco]: \u001b[0mLoaded 86 images in COCO format from C:\\Users\\main laptop\\programation\\Study\\baechlor arbeit\\bollard\\images\\bollard6\\instances_bollard6.json\n",
      "\u001b[32m[10/16 18:57:36 d2.data.build]: \u001b[0mDistribution of instances among all 1 categories:\n",
      "\u001b[36m|  category  | #instances   |\n",
      "|:----------:|:-------------|\n",
      "|    rope    | 124          |\n",
      "|            |              |\u001b[0m\n",
      "\u001b[32m[10/16 18:57:36 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/16 18:57:36 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[10/16 18:57:36 d2.data.common]: \u001b[0mSerializing 86 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/16 18:57:36 d2.data.common]: \u001b[0mSerialized dataset takes 0.58 MiB\n",
      "\u001b[32m[10/16 18:57:36 d2.evaluation.evaluator]: \u001b[0mStart inference on 86 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\torch\\functional.py:539: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\native\\TensorShape.cpp:3638.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[10/16 18:57:46 d2.evaluation.evaluator]: \u001b[0mInference done 11/86. Dataloading: 0.0008 s/iter. Inference: 0.1781 s/iter. Eval: 0.0037 s/iter. Total: 0.1827 s/iter. ETA=0:00:13\n",
      "\u001b[32m[10/16 18:57:51 d2.evaluation.evaluator]: \u001b[0mInference done 37/86. Dataloading: 0.0011 s/iter. Inference: 0.1809 s/iter. Eval: 0.0098 s/iter. Total: 0.1919 s/iter. ETA=0:00:09\n",
      "\u001b[32m[10/16 18:57:56 d2.evaluation.evaluator]: \u001b[0mInference done 63/86. Dataloading: 0.0011 s/iter. Inference: 0.1824 s/iter. Eval: 0.0104 s/iter. Total: 0.1940 s/iter. ETA=0:00:04\n",
      "\u001b[32m[10/16 18:58:01 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:16.670323 (0.205806 s / iter per device, on 1 devices)\n",
      "\u001b[32m[10/16 18:58:01 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:14 (0.184131 s / iter per device, on 1 devices)\n",
      "\u001b[32m[10/16 18:58:01 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/16 18:58:01 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to C:\\Users\\main laptop\\programation\\Study\\baechlor arbeit\\segmentation model\\output\\coco_instances_results.json\n",
      "\u001b[32m[10/16 18:58:01 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with official COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.04s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.01s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.405\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.688\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.411\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.247\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.426\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.429\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.473\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.473\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.267\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.498\n",
      "\u001b[32m[10/16 18:58:02 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 40.519 | 68.774 | 41.095 | 0.000 | 24.653 | 42.573 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *segm*\n",
      "DONE (t=0.06s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.01s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.155\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.436\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.082\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.217\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.159\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.248\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.267\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.267\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.244\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.273\n",
      "\u001b[32m[10/16 18:58:02 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 15.451 | 43.589 | 8.174  | 0.000 | 21.700 | 15.868 |\n",
      "OrderedDict({'bbox': {'AP': 40.51888218547619, 'AP50': 68.77441180660178, 'AP75': 41.09451471382021, 'APs': 0.0, 'APm': 24.653465346534652, 'APl': 42.57291308519877}, 'segm': {'AP': 15.451297959387384, 'AP50': 43.589344556556625, 'AP75': 8.173528761361862, 'APs': 0.0, 'APm': 21.699669966996694, 'APl': 15.867790875568916}})\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
    "from detectron2.data import build_detection_test_loader\n",
    "predictor = DefaultPredictor(cfg)\n",
    "evaluator = COCOEvaluator(\"my_dataset_test\", output_dir=cfg.OUTPUT_DIR)\n",
    "val_loader = build_detection_test_loader(cfg, \"my_dataset_test\")\n",
    "print(inference_on_dataset(predictor.model, val_loader, evaluator))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## evaluate directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 9113,
     "status": "ok",
     "timestamp": 1611054222745,
     "user": {
      "displayName": "Бузин Глеб Борисович",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gie_U-wtf3incY-prfOKwdA_OjgoEEDivcIJ7cJ=s64",
      "userId": "05572211529618585037"
     },
     "user_tz": -180
    },
    "id": "h9tECBQCvMv3",
    "outputId": "85117ad2-dbc2-4842-da65-cf33807a5704",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from detectron2.utils.visualizer import ColorMode\n",
    "import glob\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5\n",
    "cfg.MODEL.MASK_ON = True\n",
    "cfg.MODEL.MASK_FORMAT = \"bitmask\"\n",
    "predictor = DefaultPredictor(cfg)\n",
    "for imageName in glob.glob(r\"C:\\Users\\main laptop\\programation\\Study\\baechlor arbeit\\bollard\\images\\bollard6\\pollerCroppedDirection\\*jpg\"):\n",
    "  im = cv2.imread(imageName)\n",
    "  outputs = predictor(im)\n",
    "  v = Visualizer(im[:, :, ::-1],\n",
    "                metadata=train_metadata,\n",
    "                scale=0.8\n",
    "                 )\n",
    "  out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
    "  cv2_imshow(out.get_image()[:, :, ::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 1106780,
     "sourceId": 1860019,
     "sourceType": "datasetVersion"
    }
   ],
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
